time="2025-12-31T15:55:13Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-etcd  Stopping
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T15:55:14Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
time="2025-12-31T15:55:14Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
time="2025-12-31T15:55:14Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
time="2025-12-31T15:55:14Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
time="2025-12-31T15:55:14Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container milvus-etcd  Creating
 Container milvus-minio  Creating
 Container milvus-etcd  Created
 Container milvus-minio  Created
 Container milvus-standalone  Creating
 Container milvus-standalone  Created
 Container attu  Creating
 Container attu  Created
 Container milvus-minio  Starting
 Container milvus-etcd  Starting
 Container milvus-minio  Started
 Container milvus-etcd  Started
 Container milvus-standalone  Starting
 Container milvus-standalone  Started
 Container attu  Starting
 Container attu  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: milvus
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: milvus on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Milvus: Inserting 1000000 vectors in batches...
   Inserted batch 0 to 10000   Inserted batch 10000 to 20000   Inserted batch 20000 to 30000   Inserted batch 30000 to 40000   Inserted batch 40000 to 50000   Inserted batch 50000 to 60000   Inserted batch 60000 to 70000   Inserted batch 70000 to 80000   Inserted batch 80000 to 90000   Inserted batch 90000 to 100000   Inserted batch 100000 to 110000   Inserted batch 110000 to 120000   Inserted batch 120000 to 130000   Inserted batch 130000 to 140000   Inserted batch 140000 to 150000   Inserted batch 150000 to 160000   Inserted batch 160000 to 170000   Inserted batch 170000 to 180000   Inserted batch 180000 to 190000   Inserted batch 190000 to 200000   Inserted batch 200000 to 210000   Inserted batch 210000 to 220000   Inserted batch 220000 to 230000   Inserted batch 230000 to 240000   Inserted batch 240000 to 250000   Inserted batch 250000 to 260000   Inserted batch 260000 to 270000   Inserted batch 270000 to 280000   Inserted batch 280000 to 290000   Inserted batch 290000 to 300000   Inserted batch 300000 to 310000   Inserted batch 310000 to 320000   Inserted batch 320000 to 330000   Inserted batch 330000 to 340000   Inserted batch 340000 to 350000   Inserted batch 350000 to 360000   Inserted batch 360000 to 370000   Inserted batch 370000 to 380000   Inserted batch 380000 to 390000   Inserted batch 390000 to 400000   Inserted batch 400000 to 410000   Inserted batch 410000 to 420000   Inserted batch 420000 to 430000   Inserted batch 430000 to 440000   Inserted batch 440000 to 450000   Inserted batch 450000 to 460000   Inserted batch 460000 to 470000   Inserted batch 470000 to 480000   Inserted batch 480000 to 490000   Inserted batch 490000 to 500000   Inserted batch 500000 to 510000   Inserted batch 510000 to 520000   Inserted batch 520000 to 530000   Inserted batch 530000 to 540000   Inserted batch 540000 to 550000   Inserted batch 550000 to 560000   Inserted batch 560000 to 570000   Inserted batch 570000 to 580000   Inserted batch 580000 to 590000   Inserted batch 590000 to 600000   Inserted batch 600000 to 610000   Inserted batch 610000 to 620000   Inserted batch 620000 to 630000   Inserted batch 630000 to 640000   Inserted batch 640000 to 650000   Inserted batch 650000 to 660000   Inserted batch 660000 to 670000   Inserted batch 670000 to 680000   Inserted batch 680000 to 690000   Inserted batch 690000 to 700000   Inserted batch 700000 to 710000   Inserted batch 710000 to 720000   Inserted batch 720000 to 730000   Inserted batch 730000 to 740000   Inserted batch 740000 to 750000   Inserted batch 750000 to 760000   Inserted batch 760000 to 770000   Inserted batch 770000 to 780000   Inserted batch 780000 to 790000   Inserted batch 790000 to 800000   Inserted batch 800000 to 810000   Inserted batch 810000 to 820000   Inserted batch 820000 to 830000   Inserted batch 830000 to 840000   Inserted batch 840000 to 850000   Inserted batch 850000 to 860000   Inserted batch 860000 to 870000   Inserted batch 870000 to 880000   Inserted batch 880000 to 890000   Inserted batch 890000 to 900000   Inserted batch 900000 to 910000   Inserted batch 910000 to 920000   Inserted batch 920000 to 930000   Inserted batch 930000 to 940000   Inserted batch 940000 to 950000   Inserted batch 950000 to 960000   Inserted batch 960000 to 970000   Inserted batch 970000 to 980000   Inserted batch 980000 to 990000   Inserted batch 990000 to 1000000
‚úÖ Insertion complete.
üî® Milvus: Building index (HNSW)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...2025-12-31 16:01:34,857 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:01:34.220937', 'RPC error': '2025-12-31 16:01:34.851635'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 0 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 1 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2/3: Searching...2025-12-31 16:01:35,481 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:01:34.870848', 'RPC error': '2025-12-31 16:01:35.480067'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 1 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3/3: Searching...2025-12-31 16:01:36,106 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:01:35.489377', 'RPC error': '2025-12-31 16:01:36.105793'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 2 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(96) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463259963844460925v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
  Applying tuned parameters for sift1m
  Skipping HNSW_Cosine: Metric mismatch
Exported JSON to results/milvus/sift1m_milvus_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:01:36Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:01:53Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container milvus-minio  Creating
 Container milvus-etcd  Creating
 Container milvus-etcd  Created
 Container milvus-minio  Created
 Container milvus-standalone  Creating
 Container milvus-standalone  Created
 Container attu  Creating
 Container attu  Created
 Container milvus-minio  Starting
 Container milvus-etcd  Starting
 Container milvus-minio  Started
 Container milvus-etcd  Started
 Container milvus-standalone  Starting
 Container milvus-standalone  Started
 Container attu  Starting
 Container attu  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: milvus
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: milvus on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Milvus: Inserting 1000000 vectors in batches...
   Inserted batch 0 to 10000   Inserted batch 10000 to 20000   Inserted batch 20000 to 30000   Inserted batch 30000 to 40000   Inserted batch 40000 to 50000   Inserted batch 50000 to 60000   Inserted batch 60000 to 70000   Inserted batch 70000 to 80000   Inserted batch 80000 to 90000   Inserted batch 90000 to 100000   Inserted batch 100000 to 110000   Inserted batch 110000 to 120000   Inserted batch 120000 to 130000   Inserted batch 130000 to 140000   Inserted batch 140000 to 150000   Inserted batch 150000 to 160000   Inserted batch 160000 to 170000   Inserted batch 170000 to 180000   Inserted batch 180000 to 190000   Inserted batch 190000 to 200000   Inserted batch 200000 to 210000   Inserted batch 210000 to 220000   Inserted batch 220000 to 230000   Inserted batch 230000 to 240000   Inserted batch 240000 to 250000   Inserted batch 250000 to 260000   Inserted batch 260000 to 270000   Inserted batch 270000 to 280000   Inserted batch 280000 to 290000   Inserted batch 290000 to 300000   Inserted batch 300000 to 310000   Inserted batch 310000 to 320000   Inserted batch 320000 to 330000   Inserted batch 330000 to 340000   Inserted batch 340000 to 350000   Inserted batch 350000 to 360000   Inserted batch 360000 to 370000   Inserted batch 370000 to 380000   Inserted batch 380000 to 390000   Inserted batch 390000 to 400000   Inserted batch 400000 to 410000   Inserted batch 410000 to 420000   Inserted batch 420000 to 430000   Inserted batch 430000 to 440000   Inserted batch 440000 to 450000   Inserted batch 450000 to 460000   Inserted batch 460000 to 470000   Inserted batch 470000 to 480000   Inserted batch 480000 to 490000   Inserted batch 490000 to 500000   Inserted batch 500000 to 510000   Inserted batch 510000 to 520000   Inserted batch 520000 to 530000   Inserted batch 530000 to 540000   Inserted batch 540000 to 550000   Inserted batch 550000 to 560000   Inserted batch 560000 to 570000   Inserted batch 570000 to 580000   Inserted batch 580000 to 590000   Inserted batch 590000 to 600000   Inserted batch 600000 to 610000   Inserted batch 610000 to 620000   Inserted batch 620000 to 630000   Inserted batch 630000 to 640000   Inserted batch 640000 to 650000   Inserted batch 650000 to 660000   Inserted batch 660000 to 670000   Inserted batch 670000 to 680000   Inserted batch 680000 to 690000   Inserted batch 690000 to 700000   Inserted batch 700000 to 710000   Inserted batch 710000 to 720000   Inserted batch 720000 to 730000   Inserted batch 730000 to 740000   Inserted batch 740000 to 750000   Inserted batch 750000 to 760000   Inserted batch 760000 to 770000   Inserted batch 770000 to 780000   Inserted batch 780000 to 790000   Inserted batch 790000 to 800000   Inserted batch 800000 to 810000   Inserted batch 810000 to 820000   Inserted batch 820000 to 830000   Inserted batch 830000 to 840000   Inserted batch 840000 to 850000   Inserted batch 850000 to 860000   Inserted batch 860000 to 870000   Inserted batch 870000 to 880000   Inserted batch 880000 to 890000   Inserted batch 890000 to 900000   Inserted batch 900000 to 910000   Inserted batch 910000 to 920000   Inserted batch 920000 to 930000   Inserted batch 930000 to 940000   Inserted batch 940000 to 950000   Inserted batch 950000 to 960000   Inserted batch 960000 to 970000   Inserted batch 970000 to 980000   Inserted batch 980000 to 990000   Inserted batch 990000 to 1000000
‚úÖ Insertion complete.
üî® Milvus: Building index (HNSW)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...2025-12-31 16:05:15,296 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:05:14.686170', 'RPC error': '2025-12-31 16:05:15.294462'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 0 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 1 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2/3: Searching...2025-12-31 16:05:15,910 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:05:15.301761', 'RPC error': '2025-12-31 16:05:15.910001'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 1 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3/3: Searching...2025-12-31 16:05:16,526 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:05:15.916273', 'RPC error': '2025-12-31 16:05:16.525149'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 2 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(64) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260068112236626v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
  Applying tuned parameters for deep1m
  Skipping HNSW_Cosine: Metric mismatch
Exported JSON to results/milvus/deep1m_milvus_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:05:17Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:05:23Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container milvus-minio  Creating
 Container milvus-etcd  Creating
 Container milvus-etcd  Created
 Container milvus-minio  Created
 Container milvus-standalone  Creating
 Container milvus-standalone  Created
 Container attu  Creating
 Container attu  Created
 Container milvus-etcd  Starting
 Container milvus-minio  Starting
 Container milvus-etcd  Started
 Container milvus-minio  Started
 Container milvus-standalone  Starting
 Container milvus-standalone  Started
 Container attu  Starting
 Container attu  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: milvus
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: milvus on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Milvus: Inserting 1000000 vectors in batches...
   Inserted batch 0 to 10000   Inserted batch 10000 to 20000   Inserted batch 20000 to 30000   Inserted batch 30000 to 40000   Inserted batch 40000 to 50000   Inserted batch 50000 to 60000   Inserted batch 60000 to 70000   Inserted batch 70000 to 80000   Inserted batch 80000 to 90000   Inserted batch 90000 to 100000   Inserted batch 100000 to 110000   Inserted batch 110000 to 120000   Inserted batch 120000 to 130000   Inserted batch 130000 to 140000   Inserted batch 140000 to 150000   Inserted batch 150000 to 160000   Inserted batch 160000 to 170000   Inserted batch 170000 to 180000   Inserted batch 180000 to 190000   Inserted batch 190000 to 200000   Inserted batch 200000 to 210000   Inserted batch 210000 to 220000   Inserted batch 220000 to 230000   Inserted batch 230000 to 240000   Inserted batch 240000 to 250000   Inserted batch 250000 to 260000   Inserted batch 260000 to 270000   Inserted batch 270000 to 280000   Inserted batch 280000 to 290000   Inserted batch 290000 to 300000   Inserted batch 300000 to 310000   Inserted batch 310000 to 320000   Inserted batch 320000 to 330000   Inserted batch 330000 to 340000   Inserted batch 340000 to 350000   Inserted batch 350000 to 360000   Inserted batch 360000 to 370000   Inserted batch 370000 to 380000   Inserted batch 380000 to 390000   Inserted batch 390000 to 400000   Inserted batch 400000 to 410000   Inserted batch 410000 to 420000   Inserted batch 420000 to 430000   Inserted batch 430000 to 440000   Inserted batch 440000 to 450000   Inserted batch 450000 to 460000   Inserted batch 460000 to 470000   Inserted batch 470000 to 480000   Inserted batch 480000 to 490000   Inserted batch 490000 to 500000   Inserted batch 500000 to 510000   Inserted batch 510000 to 520000   Inserted batch 520000 to 530000   Inserted batch 530000 to 540000   Inserted batch 540000 to 550000   Inserted batch 550000 to 560000   Inserted batch 560000 to 570000   Inserted batch 570000 to 580000   Inserted batch 580000 to 590000   Inserted batch 590000 to 600000   Inserted batch 600000 to 610000   Inserted batch 610000 to 620000   Inserted batch 620000 to 630000   Inserted batch 630000 to 640000   Inserted batch 640000 to 650000   Inserted batch 650000 to 660000   Inserted batch 660000 to 670000   Inserted batch 670000 to 680000   Inserted batch 680000 to 690000   Inserted batch 690000 to 700000   Inserted batch 700000 to 710000   Inserted batch 710000 to 720000   Inserted batch 720000 to 730000   Inserted batch 730000 to 740000   Inserted batch 740000 to 750000   Inserted batch 750000 to 760000   Inserted batch 760000 to 770000   Inserted batch 770000 to 780000   Inserted batch 780000 to 790000   Inserted batch 790000 to 800000   Inserted batch 800000 to 810000   Inserted batch 810000 to 820000   Inserted batch 820000 to 830000   Inserted batch 830000 to 840000   Inserted batch 840000 to 850000   Inserted batch 850000 to 860000   Inserted batch 860000 to 870000   Inserted batch 870000 to 880000   Inserted batch 880000 to 890000   Inserted batch 890000 to 900000   Inserted batch 900000 to 910000   Inserted batch 910000 to 920000   Inserted batch 920000 to 930000   Inserted batch 930000 to 940000   Inserted batch 940000 to 950000   Inserted batch 950000 to 960000   Inserted batch 960000 to 970000   Inserted batch 970000 to 980000   Inserted batch 980000 to 990000   Inserted batch 990000 to 1000000
‚úÖ Insertion complete.
üî® Milvus: Building index (HNSW)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...2025-12-31 16:12:33,700 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:12:33.057834', 'RPC error': '2025-12-31 16:12:33.688491'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 0 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 1 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2/3: Searching...2025-12-31 16:12:34,335 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:12:33.721349', 'RPC error': '2025-12-31 16:12:34.334407'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 1 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 2 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3/3: Searching...2025-12-31 16:12:34,962 [ERROR][handler]: RPC error: [search], <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>, <Time:{'RPC start': '2025-12-31 16:12:34.347074', 'RPC error': '2025-12-31 16:12:34.961193'}>
Traceback:
Traceback (most recent call last):
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
 (decorators.py:267)
Search run 2 failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/milvus_adapter.py", line 254, in search
    res = self._collection.search(
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/orm/collection.py", line 812, in search
    resp = conn.search(
           ^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 271, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 263, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 322, in handler
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 196, in handler
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/decorators.py", line 166, in handler
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 1041, in search
    return self._execute_search(request, timeout, round_decimal=round_decimal, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 974, in _execute_search
    raise e from e
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/grpc_handler.py", line 963, in _execute_search
    check_status(response.status)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/pymilvus/client/utils.py", line 66, in check_status
    raise MilvusException(status.code, status.reason, status.error_code)
pymilvus.exceptions.MilvusException: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no available shard delegator found: service unavailable: fail to search on all shard leaders)>
    Run 3 Failed: <MilvusException: (code=0, message=attempt #0: fail to Search, QueryNode ID=1, 
reason=worker(1) query failed: UnexpectedError: Assert "failed to search: out of range in json: ef(48) should 
be larger than k(100)" at /go/src/github.com/milvus-io/milvus/internal/core/src/index/VectorMemIndex.cpp:319: 
channel=by-dev-rootcoord-dml_0_463260123173486974v0: fail to search/query shard leader: attempt #1: no 
available shard delegator found: service unavailable: fail to search on all shard leaders)>
  Applying tuned parameters for random
  Skipping HNSW_Cosine: Metric mismatch
Exported JSON to results/milvus/random_milvus_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:12:35Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-etcd  Stopping
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:12:52Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container milvus-minio  Creating
 Container milvus-etcd  Creating
 Container milvus-etcd  Created
 Container milvus-minio  Created
 Container milvus-standalone  Creating
 Container milvus-standalone  Created
 Container attu  Creating
 Container attu  Created
 Container milvus-etcd  Starting
 Container milvus-minio  Starting
 Container milvus-etcd  Started
 Container milvus-minio  Started
 Container milvus-standalone  Starting
 Container milvus-standalone  Started
 Container attu  Starting
 Container attu  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: milvus
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: milvus on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Milvus: Inserting 100000 vectors in batches...
   Inserted batch 0 to 10000   Inserted batch 10000 to 20000   Inserted batch 20000 to 30000   Inserted batch 30000 to 40000   Inserted batch 40000 to 50000   Inserted batch 50000 to 60000   Inserted batch 60000 to 70000   Inserted batch 70000 to 80000   Inserted batch 80000 to 90000   Inserted batch 90000 to 100000
‚úÖ Insertion complete.
üî® Milvus: Building index (HNSW)...
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 1: Recall@10=1.0000, Latency_p50=8.28ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=9.54ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=13.91ms
    Results: milvus_msmarco (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9860 ¬± 0.0002    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 10.5754 ¬± 2.9530   ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 27.8882 ¬± 19.7697  ‚îÇ
‚îÇ QPS              ‚îÇ 93.4465 ¬± 24.3947  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 118.6109 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/milvus/msmarco_milvus_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:16:23Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:16:40Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container milvus-etcd  Creating
 Container milvus-minio  Creating
 Container milvus-etcd  Created
 Container milvus-minio  Created
 Container milvus-standalone  Creating
 Container milvus-standalone  Created
 Container attu  Creating
 Container attu  Created
 Container milvus-etcd  Starting
 Container milvus-minio  Starting
 Container milvus-etcd  Started
 Container milvus-minio  Started
 Container milvus-standalone  Starting
 Container milvus-standalone  Started
 Container attu  Starting
 Container attu  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: milvus
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: milvus on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Milvus: Inserting 390000 vectors in batches...
   Inserted batch 0 to 10000   Inserted batch 10000 to 20000   Inserted batch 20000 to 30000   Inserted batch 30000 to 40000   Inserted batch 40000 to 50000   Inserted batch 50000 to 60000   Inserted batch 60000 to 70000   Inserted batch 70000 to 80000   Inserted batch 80000 to 90000   Inserted batch 90000 to 100000   Inserted batch 100000 to 110000   Inserted batch 110000 to 120000   Inserted batch 120000 to 130000   Inserted batch 130000 to 140000   Inserted batch 140000 to 150000   Inserted batch 150000 to 160000   Inserted batch 160000 to 170000   Inserted batch 170000 to 180000   Inserted batch 180000 to 190000   Inserted batch 190000 to 200000   Inserted batch 200000 to 210000   Inserted batch 210000 to 220000   Inserted batch 220000 to 230000   Inserted batch 230000 to 240000   Inserted batch 240000 to 250000   Inserted batch 250000 to 260000   Inserted batch 260000 to 270000   Inserted batch 270000 to 280000   Inserted batch 280000 to 290000   Inserted batch 290000 to 300000   Inserted batch 300000 to 310000   Inserted batch 310000 to 320000   Inserted batch 320000 to 330000   Inserted batch 330000 to 340000   Inserted batch 340000 to 350000   Inserted batch 350000 to 360000   Inserted batch 360000 to 370000   Inserted batch 370000 to 380000   Inserted batch 380000 to 390000
‚úÖ Insertion complete.
üî® Milvus: Building index (HNSW)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=1.0000, Latency_p50=6.27ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=1.0000, Latency_p50=6.13ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=1.0000, Latency_p50=6.18ms
     Results: milvus_glove (runs=3)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9466 ¬± 0.0003    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 6.1927 ¬± 0.0732    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 8.7529 ¬± 0.4078    ‚îÇ
‚îÇ QPS              ‚îÇ 159.1038 ¬± 2.4748  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 163.6492 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/milvus/glove_milvus_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:30:54Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/milvus-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container attu  Stopping
 Container attu  Stopped
 Container attu  Removing
 Container attu  Removed
 Container milvus-standalone  Stopping
 Container milvus-standalone  Stopped
 Container milvus-standalone  Removing
 Container milvus-standalone  Removed
 Container milvus-minio  Stopping
 Container milvus-etcd  Stopping
 Container milvus-etcd  Stopped
 Container milvus-etcd  Removing
 Container milvus-etcd  Removed
 Container milvus-minio  Stopped
 Container milvus-minio  Removing
 Container milvus-minio  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:30:55Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container qdrant_benchmark  Creating
 Container qdrant_benchmark  Created
 Container qdrant_benchmark  Starting
 Container qdrant_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: qdrant
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: qdrant on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Using Safe Upload for 1000000 vectors...
‚è≥ Waiting for Qdrant indexing...
   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...
‚úÖ Optimization complete. Collection is GREEN.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=1.0000, Latency_p50=6.85ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=5.16ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=5.30ms
  Applying tuned parameters for sift1m
  Skipping HNSW_Cosine: Metric mismatch
     Results: qdrant_sift1m (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9341 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.7722 ¬± 0.9386    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 39.3525 ¬± 56.5474  ‚îÇ
‚îÇ QPS              ‚îÇ 158.3362 ¬± 53.2218 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 658.1120 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/qdrant/sift1m_qdrant_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:47:44Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container qdrant_benchmark  Stopping
 Container qdrant_benchmark  Stopped
 Container qdrant_benchmark  Removing
 Container qdrant_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:47:49Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container qdrant_benchmark  Creating
 Container qdrant_benchmark  Created
 Container qdrant_benchmark  Starting
 Container qdrant_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: qdrant
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: qdrant on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Using Safe Upload for 1000000 vectors...
‚è≥ Waiting for Qdrant indexing...
   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...
‚úÖ Optimization complete. Collection is GREEN.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=0.9999, Latency_p50=4.96ms
    Run 2/3: Searching...    Run 2: Recall@10=0.9999, Latency_p50=4.94ms
    Run 3/3: Searching...    Run 3: Recall@10=0.9999, Latency_p50=5.03ms
  Applying tuned parameters for deep1m
  Skipping HNSW_Cosine: Metric mismatch
     Results: qdrant_deep1m (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9183 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 4.9744 ¬± 0.0471    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 6.5548 ¬± 0.3864    ‚îÇ
‚îÇ QPS              ‚îÇ 198.5594 ¬± 0.9974  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 464.8084 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/qdrant/deep1m_qdrant_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T16:59:21Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container qdrant_benchmark  Stopping
 Container qdrant_benchmark  Stopped
 Container qdrant_benchmark  Removing
 Container qdrant_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T16:59:27Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container qdrant_benchmark  Creating
 Container qdrant_benchmark  Created
 Container qdrant_benchmark  Starting
 Container qdrant_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: qdrant
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: qdrant on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Using Safe Upload for 1000000 vectors...
‚è≥ Waiting for Qdrant indexing...
   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...
‚úÖ Optimization complete. Collection is GREEN.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=0.9992, Latency_p50=5.84ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=0.9992, Latency_p50=5.77ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=0.9992, Latency_p50=5.84ms
  Applying tuned parameters for random
  Skipping HNSW_Cosine: Metric mismatch
     Results: qdrant_random (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9992 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.2154 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.8139 ¬± 0.0411    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 7.6838 ¬± 0.4182    ‚îÇ
‚îÇ QPS              ‚îÇ 169.1562 ¬± 2.1522  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 677.6901 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/qdrant/random_qdrant_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T17:15:55Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container qdrant_benchmark  Stopping
 Container qdrant_benchmark  Stopped
 Container qdrant_benchmark  Removing
 Container qdrant_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T17:16:00Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container qdrant_benchmark  Creating
 Container qdrant_benchmark  Created
 Container qdrant_benchmark  Starting
 Container qdrant_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: qdrant
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: qdrant on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: HNSW_Cosine
    Building Index (Once)...
‚ö° Auto-enabling Scalar Quantization (Int8) for speed & memory safety...
üöÄ Using Safe Upload for 100000 vectors...
‚è≥ Waiting for Qdrant indexing...
   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...
‚úÖ Optimization complete. Collection is GREEN.
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 1: Recall@10=1.0000, Latency_p50=6.69ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=6.61ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=6.59ms
    Results: qdrant_msmarco (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9558 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 6.6277 ¬± 0.0502    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 9.8475 ¬± 3.1515    ‚îÇ
‚îÇ QPS              ‚îÇ 148.3698 ¬± 2.7607  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 130.6422 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/qdrant/msmarco_qdrant_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T17:19:50Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container qdrant_benchmark  Stopping
 Container qdrant_benchmark  Stopped
 Container qdrant_benchmark  Removing
 Container qdrant_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T17:19:55Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container qdrant_benchmark  Creating
 Container qdrant_benchmark  Created
 Container qdrant_benchmark  Starting
 Container qdrant_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: qdrant
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: qdrant on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Using Safe Upload for 390000 vectors...
‚è≥ Waiting for Qdrant indexing...
   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...   Status: yellow (Optimizing)...
‚úÖ Optimization complete. Collection is GREEN.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=1.0000, Latency_p50=5.41ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=1.0000, Latency_p50=5.40ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=1.0000, Latency_p50=5.29ms
     Results: qdrant_glove (runs=3)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9307 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.3688 ¬± 0.0678    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 7.0987 ¬± 0.6003    ‚îÇ
‚îÇ QPS              ‚îÇ 184.1375 ¬± 3.2545  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 287.4146 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/qdrant/glove_qdrant_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T17:36:22Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/qdrant-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container qdrant_benchmark  Stopping
 Container qdrant_benchmark  Stopped
 Container qdrant_benchmark  Removing
 Container qdrant_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T17:36:22Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container ragdbeval-weaviate-1  Creating
 Container ragdbeval-weaviate-1  Created
 Container ragdbeval-weaviate-1  Starting
 Container ragdbeval-weaviate-1  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: weaviate
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: weaviate on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: HNSW_L2
    Building Index (Once)...
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:206: DeprecationWarning: Dep025: You are using the `vector_index_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead defining `vector_index_config` as a sub-argument.
            
  warnings.warn(
üöÄ Weaviate: Inserting 1000000 vectors (Fixed Batch Mode)...
   Processed 10000 vectors...   Processed 20000 vectors...   Processed 30000 vectors...   Processed 40000 vectors...   Processed 50000 vectors...   Processed 60000 vectors...   Processed 70000 vectors...   Processed 80000 vectors...   Processed 90000 vectors...   Processed 100000 vectors...   Processed 110000 vectors...   Processed 120000 vectors...   Processed 130000 vectors...   Processed 140000 vectors...   Processed 150000 vectors...   Processed 160000 vectors...   Processed 170000 vectors...   Processed 180000 vectors...   Processed 190000 vectors...   Processed 200000 vectors...   Processed 210000 vectors...   Processed 220000 vectors...   Processed 230000 vectors...   Processed 240000 vectors...   Processed 250000 vectors...   Processed 260000 vectors...   Processed 270000 vectors...   Processed 280000 vectors...   Processed 290000 vectors...   Processed 300000 vectors...   Processed 310000 vectors...   Processed 320000 vectors...   Processed 330000 vectors...   Processed 340000 vectors...   Processed 350000 vectors...   Processed 360000 vectors...   Processed 370000 vectors...   Processed 380000 vectors...   Processed 390000 vectors...   Processed 400000 vectors...   Processed 410000 vectors...   Processed 420000 vectors...   Processed 430000 vectors...   Processed 440000 vectors...   Processed 450000 vectors...   Processed 460000 vectors...   Processed 470000 vectors...   Processed 480000 vectors...   Processed 490000 vectors...   Processed 500000 vectors...   Processed 510000 vectors...   Processed 520000 vectors...   Processed 530000 vectors...   Processed 540000 vectors...   Processed 550000 vectors...   Processed 560000 vectors...   Processed 570000 vectors...   Processed 580000 vectors...   Processed 590000 vectors...   Processed 600000 vectors...   Processed 610000 vectors...   Processed 620000 vectors...   Processed 630000 vectors...   Processed 640000 vectors...   Processed 650000 vectors...   Processed 660000 vectors...   Processed 670000 vectors...   Processed 680000 vectors...   Processed 690000 vectors...   Processed 700000 vectors...   Processed 710000 vectors...   Processed 720000 vectors...   Processed 730000 vectors...   Processed 740000 vectors...   Processed 750000 vectors...   Processed 760000 vectors...   Processed 770000 vectors...   Processed 780000 vectors...   Processed 790000 vectors...   Processed 800000 vectors...   Processed 810000 vectors...   Processed 820000 vectors...   Processed 830000 vectors...   Processed 840000 vectors...   Processed 850000 vectors...   Processed 860000 vectors...   Processed 870000 vectors...   Processed 880000 vectors...   Processed 890000 vectors...   Processed 900000 vectors...   Processed 910000 vectors...   Processed 920000 vectors...   Processed 930000 vectors...   Processed 940000 vectors...   Processed 950000 vectors...   Processed 960000 vectors...   Processed 970000 vectors...   Processed 980000 vectors...   Processed 990000 vectors...
‚è≥ Weaviate: Waiting for indexing (Shards READY)...
‚úÖ All shards READY.
    ‚è≥ Weaviate: Sleeping 300s for HNSW convergence...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching.../home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:135: DeprecationWarning: Dep017: You are using the `vector_index_config` argument in the `collection.config.update()` method, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
    Run 1: Recall@10=1.0000, Latency_p50=7.39ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=7.20ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=7.21ms
  Applying tuned parameters for sift1m
  Skipping HNSW_Cosine: Metric mismatch
    Results: weaviate_sift1m (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9237 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 7.2668 ¬± 0.1071    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 11.8986 ¬± 0.8651   ‚îÇ
‚îÇ QPS              ‚îÇ 133.4245 ¬± 3.4483  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 873.4838 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/weaviate/sift1m_weaviate_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T18:01:57Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container ragdbeval-weaviate-1  Stopping
 Container ragdbeval-weaviate-1  Stopped
 Container ragdbeval-weaviate-1  Removing
 Container ragdbeval-weaviate-1  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T18:02:04Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container ragdbeval-weaviate-1  Creating
 Container ragdbeval-weaviate-1  Created
 Container ragdbeval-weaviate-1  Starting
 Container ragdbeval-weaviate-1  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: weaviate
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: weaviate on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: HNSW_L2
    Building Index (Once)...
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:206: DeprecationWarning: Dep025: You are using the `vector_index_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead defining `vector_index_config` as a sub-argument.
            
  warnings.warn(
üöÄ Weaviate: Inserting 1000000 vectors (Fixed Batch Mode)...
   Processed 10000 vectors...   Processed 20000 vectors...   Processed 30000 vectors...   Processed 40000 vectors...   Processed 50000 vectors...   Processed 60000 vectors...   Processed 70000 vectors...   Processed 80000 vectors...   Processed 90000 vectors...   Processed 100000 vectors...   Processed 110000 vectors...   Processed 120000 vectors...   Processed 130000 vectors...   Processed 140000 vectors...   Processed 150000 vectors...   Processed 160000 vectors...   Processed 170000 vectors...   Processed 180000 vectors...   Processed 190000 vectors...   Processed 200000 vectors...   Processed 210000 vectors...   Processed 220000 vectors...   Processed 230000 vectors...   Processed 240000 vectors...   Processed 250000 vectors...   Processed 260000 vectors...   Processed 270000 vectors...   Processed 280000 vectors...   Processed 290000 vectors...   Processed 300000 vectors...   Processed 310000 vectors...   Processed 320000 vectors...   Processed 330000 vectors...   Processed 340000 vectors...   Processed 350000 vectors...   Processed 360000 vectors...   Processed 370000 vectors...   Processed 380000 vectors...   Processed 390000 vectors...   Processed 400000 vectors...   Processed 410000 vectors...   Processed 420000 vectors...   Processed 430000 vectors...   Processed 440000 vectors...   Processed 450000 vectors...   Processed 460000 vectors...   Processed 470000 vectors...   Processed 480000 vectors...   Processed 490000 vectors...   Processed 500000 vectors...   Processed 510000 vectors...   Processed 520000 vectors...   Processed 530000 vectors...   Processed 540000 vectors...   Processed 550000 vectors...   Processed 560000 vectors...   Processed 570000 vectors...   Processed 580000 vectors...   Processed 590000 vectors...   Processed 600000 vectors...   Processed 610000 vectors...   Processed 620000 vectors...   Processed 630000 vectors...   Processed 640000 vectors...   Processed 650000 vectors...   Processed 660000 vectors...   Processed 670000 vectors...   Processed 680000 vectors...   Processed 690000 vectors...   Processed 700000 vectors...   Processed 710000 vectors...   Processed 720000 vectors...   Processed 730000 vectors...   Processed 740000 vectors...   Processed 750000 vectors...   Processed 760000 vectors...   Processed 770000 vectors...   Processed 780000 vectors...   Processed 790000 vectors...   Processed 800000 vectors...   Processed 810000 vectors...   Processed 820000 vectors...   Processed 830000 vectors...   Processed 840000 vectors...   Processed 850000 vectors...   Processed 860000 vectors...   Processed 870000 vectors...   Processed 880000 vectors...   Processed 890000 vectors...   Processed 900000 vectors...   Processed 910000 vectors...   Processed 920000 vectors...   Processed 930000 vectors...   Processed 940000 vectors...   Processed 950000 vectors...   Processed 960000 vectors...   Processed 970000 vectors...   Processed 980000 vectors...   Processed 990000 vectors...
‚è≥ Weaviate: Waiting for indexing (Shards READY)...
‚úÖ All shards READY.
    ‚è≥ Weaviate: Sleeping 300s for HNSW convergence...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching.../home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:135: DeprecationWarning: Dep017: You are using the `vector_index_config` argument in the `collection.config.update()` method, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
    Run 1: Recall@10=1.0000, Latency_p50=7.52ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=7.21ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=7.03ms
  Applying tuned parameters for deep1m
  Skipping HNSW_Cosine: Metric mismatch
    Results: weaviate_deep1m (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9098 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 7.2510 ¬± 0.2459    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 11.7963 ¬± 0.6789   ‚îÇ
‚îÇ QPS              ‚îÇ 134.3820 ¬± 5.4682  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 658.1930 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/weaviate/deep1m_weaviate_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T18:22:59Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container ragdbeval-weaviate-1  Stopping
 Container ragdbeval-weaviate-1  Stopped
 Container ragdbeval-weaviate-1  Removing
 Container ragdbeval-weaviate-1  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T18:23:05Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container ragdbeval-weaviate-1  Creating
 Container ragdbeval-weaviate-1  Created
 Container ragdbeval-weaviate-1  Starting
 Container ragdbeval-weaviate-1  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: weaviate
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: weaviate on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: HNSW_L2
    Building Index (Once)...
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:206: DeprecationWarning: Dep025: You are using the `vector_index_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead defining `vector_index_config` as a sub-argument.
            
  warnings.warn(
üöÄ Weaviate: Inserting 1000000 vectors (Fixed Batch Mode)...
   Processed 10000 vectors...   Processed 20000 vectors...   Processed 30000 vectors...   Processed 40000 vectors...   Processed 50000 vectors...   Processed 60000 vectors...   Processed 70000 vectors...   Processed 80000 vectors...   Processed 90000 vectors...   Processed 100000 vectors...   Processed 110000 vectors...   Processed 120000 vectors...   Processed 130000 vectors...   Processed 140000 vectors...   Processed 150000 vectors...   Processed 160000 vectors...   Processed 170000 vectors...   Processed 180000 vectors...   Processed 190000 vectors...   Processed 200000 vectors...   Processed 210000 vectors...   Processed 220000 vectors...   Processed 230000 vectors...   Processed 240000 vectors...   Processed 250000 vectors...   Processed 260000 vectors...   Processed 270000 vectors...   Processed 280000 vectors...   Processed 290000 vectors...   Processed 300000 vectors...   Processed 310000 vectors...   Processed 320000 vectors...   Processed 330000 vectors...   Processed 340000 vectors...   Processed 350000 vectors...   Processed 360000 vectors...   Processed 370000 vectors...   Processed 380000 vectors...   Processed 390000 vectors...   Processed 400000 vectors...   Processed 410000 vectors...   Processed 420000 vectors...   Processed 430000 vectors...   Processed 440000 vectors...   Processed 450000 vectors...   Processed 460000 vectors...   Processed 470000 vectors...   Processed 480000 vectors...   Processed 490000 vectors...   Processed 500000 vectors...   Processed 510000 vectors...   Processed 520000 vectors...   Processed 530000 vectors...   Processed 540000 vectors...   Processed 550000 vectors...   Processed 560000 vectors...   Processed 570000 vectors...   Processed 580000 vectors...   Processed 590000 vectors...   Processed 600000 vectors...   Processed 610000 vectors...   Processed 620000 vectors...   Processed 630000 vectors...   Processed 640000 vectors...   Processed 650000 vectors...   Processed 660000 vectors...   Processed 670000 vectors...   Processed 680000 vectors...   Processed 690000 vectors...   Processed 700000 vectors...   Processed 710000 vectors...   Processed 720000 vectors...   Processed 730000 vectors...   Processed 740000 vectors...   Processed 750000 vectors...   Processed 760000 vectors...   Processed 770000 vectors...   Processed 780000 vectors...   Processed 790000 vectors...   Processed 800000 vectors...   Processed 810000 vectors...   Processed 820000 vectors...   Processed 830000 vectors...   Processed 840000 vectors...   Processed 850000 vectors...   Processed 860000 vectors...   Processed 870000 vectors...   Processed 880000 vectors...   Processed 890000 vectors...   Processed 900000 vectors...   Processed 910000 vectors...   Processed 920000 vectors...   Processed 930000 vectors...   Processed 940000 vectors...   Processed 950000 vectors...   Processed 960000 vectors...   Processed 970000 vectors...   Processed 980000 vectors...   Processed 990000 vectors...
‚è≥ Weaviate: Waiting for indexing (Shards READY)...
‚úÖ All shards READY.
    ‚è≥ Weaviate: Sleeping 300s for HNSW convergence...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching.../home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:135: DeprecationWarning: Dep017: You are using the `vector_index_config` argument in the `collection.config.update()` method, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(

    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=0.9978, Latency_p50=8.26ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=0.9978, Latency_p50=8.11ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=0.9978, Latency_p50=8.88ms
  Applying tuned parameters for random
  Skipping HNSW_Cosine: Metric mismatch
    Results: weaviate_random (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9978 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.1973 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 8.4158 ¬± 0.4064    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 15.4231 ¬± 4.8158   ‚îÇ
‚îÇ QPS              ‚îÇ 113.2757 ¬± 10.5356 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 1081.4100 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/weaviate/random_weaviate_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T18:52:54Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container ragdbeval-weaviate-1  Stopping
 Container ragdbeval-weaviate-1  Stopped
 Container ragdbeval-weaviate-1  Removing
 Container ragdbeval-weaviate-1  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T18:53:01Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container ragdbeval-weaviate-1  Creating
 Container ragdbeval-weaviate-1  Created
 Container ragdbeval-weaviate-1  Starting
 Container ragdbeval-weaviate-1  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: weaviate
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: weaviate on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: HNSW_Cosine
    Building Index (Once)...
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:206: DeprecationWarning: Dep025: You are using the `vector_index_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead defining `vector_index_config` as a sub-argument.
            
  warnings.warn(
üöÄ Weaviate: Inserting 100000 vectors (Fixed Batch Mode)...
   Processed 10000 vectors...   Processed 20000 vectors...   Processed 30000 vectors...   Processed 40000 vectors...   Processed 50000 vectors...   Processed 60000 vectors...   Processed 70000 vectors...   Processed 80000 vectors...   Processed 90000 vectors...
‚è≥ Weaviate: Waiting for indexing (Shards READY)...
‚úÖ All shards READY.
    ‚è≥ Weaviate: Sleeping 300s for HNSW convergence...
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching.../home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:135: DeprecationWarning: Dep017: You are using the `vector_index_config` argument in the `collection.config.update()` method, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(

    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 1: Recall@10=1.0000, Latency_p50=9.15ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=9.60ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=9.91ms
   Results: weaviate_msmarco (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9531 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 9.5556 ¬± 0.3824    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 14.7541 ¬± 1.5771   ‚îÇ
‚îÇ QPS              ‚îÇ 101.9149 ¬± 4.8606  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 161.0035 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/weaviate/msmarco_weaviate_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T19:02:33Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container ragdbeval-weaviate-1  Stopping
 Container ragdbeval-weaviate-1  Stopped
 Container ragdbeval-weaviate-1  Removing
 Container ragdbeval-weaviate-1  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T19:02:40Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container ragdbeval-weaviate-1  Creating
 Container ragdbeval-weaviate-1  Created
 Container ragdbeval-weaviate-1  Starting
 Container ragdbeval-weaviate-1  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: weaviate
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: weaviate on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: HNSW_Cosine
    Building Index (Once)...
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(
/home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:206: DeprecationWarning: Dep025: You are using the `vector_index_config` argument in `collection.config.create()`, which is deprecated.
            Use the `vector_config` argument instead defining `vector_index_config` as a sub-argument.
            
  warnings.warn(
üöÄ Weaviate: Inserting 390000 vectors (Fixed Batch Mode)...
   Processed 10000 vectors...   Processed 20000 vectors...   Processed 30000 vectors...   Processed 40000 vectors...   Processed 50000 vectors...   Processed 60000 vectors...   Processed 70000 vectors...   Processed 80000 vectors...   Processed 90000 vectors...   Processed 100000 vectors...   Processed 110000 vectors...   Processed 120000 vectors...   Processed 130000 vectors...   Processed 140000 vectors...   Processed 150000 vectors...   Processed 160000 vectors...   Processed 170000 vectors...   Processed 180000 vectors...   Processed 190000 vectors...   Processed 200000 vectors...   Processed 210000 vectors...   Processed 220000 vectors...   Processed 230000 vectors...   Processed 240000 vectors...   Processed 250000 vectors...   Processed 260000 vectors...   Processed 270000 vectors...   Processed 280000 vectors...   Processed 290000 vectors...   Processed 300000 vectors...   Processed 310000 vectors...   Processed 320000 vectors...   Processed 330000 vectors...   Processed 340000 vectors...   Processed 350000 vectors...   Processed 360000 vectors...   Processed 370000 vectors...   Processed 380000 vectors...
‚è≥ Weaviate: Waiting for indexing (Shards READY)...
‚úÖ All shards READY.
    ‚è≥ Weaviate: Sleeping 300s for HNSW convergence...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching.../home/ashenrashmike2000/.local/lib/python3.12/site-packages/weaviate/warnings.py:135: DeprecationWarning: Dep017: You are using the `vector_index_config` argument in the `collection.config.update()` method, which is deprecated.
            Use the `vector_config` argument instead.
            
  warnings.warn(

    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=1.0000, Latency_p50=7.92ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=1.0000, Latency_p50=7.95ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=1.0000, Latency_p50=7.62ms
    Results: weaviate_glove (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9273 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 7.8311 ¬± 0.1825    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 12.6507 ¬± 1.0560   ‚îÇ
‚îÇ QPS              ‚îÇ 124.5128 ¬± 3.7213  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 417.1286 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/weaviate/glove_weaviate_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T19:27:20Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/weaviate-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container ragdbeval-weaviate-1  Stopping
 Container ragdbeval-weaviate-1  Stopped
 Container ragdbeval-weaviate-1  Removing
 Container ragdbeval-weaviate-1  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T19:27:21Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container pgvector_benchmark  Creating
 Container pgvector_benchmark  Created
 Container pgvector_benchmark  Starting
 Container pgvector_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: pgvector
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: pgvector on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Pgvector: Inserting 1000000 vectors in batches...
   Inserted batch 10000/1000000   Inserted batch 20000/1000000   Inserted batch 30000/1000000   Inserted batch 40000/1000000   Inserted batch 50000/1000000   Inserted batch 60000/1000000   Inserted batch 70000/1000000   Inserted batch 80000/1000000   Inserted batch 90000/1000000   Inserted batch 100000/1000000   Inserted batch 110000/1000000   Inserted batch 120000/1000000   Inserted batch 130000/1000000   Inserted batch 140000/1000000   Inserted batch 150000/1000000   Inserted batch 160000/1000000   Inserted batch 170000/1000000   Inserted batch 180000/1000000   Inserted batch 190000/1000000   Inserted batch 200000/1000000   Inserted batch 210000/1000000   Inserted batch 220000/1000000   Inserted batch 230000/1000000   Inserted batch 240000/1000000   Inserted batch 250000/1000000   Inserted batch 260000/1000000   Inserted batch 270000/1000000   Inserted batch 280000/1000000   Inserted batch 290000/1000000   Inserted batch 300000/1000000   Inserted batch 310000/1000000   Inserted batch 320000/1000000   Inserted batch 330000/1000000   Inserted batch 340000/1000000   Inserted batch 350000/1000000   Inserted batch 360000/1000000   Inserted batch 370000/1000000   Inserted batch 380000/1000000   Inserted batch 390000/1000000   Inserted batch 400000/1000000   Inserted batch 410000/1000000   Inserted batch 420000/1000000   Inserted batch 430000/1000000   Inserted batch 440000/1000000   Inserted batch 450000/1000000   Inserted batch 460000/1000000   Inserted batch 470000/1000000   Inserted batch 480000/1000000   Inserted batch 490000/1000000   Inserted batch 500000/1000000   Inserted batch 510000/1000000   Inserted batch 520000/1000000   Inserted batch 530000/1000000   Inserted batch 540000/1000000   Inserted batch 550000/1000000   Inserted batch 560000/1000000   Inserted batch 570000/1000000   Inserted batch 580000/1000000   Inserted batch 590000/1000000   Inserted batch 600000/1000000   Inserted batch 610000/1000000   Inserted batch 620000/1000000   Inserted batch 630000/1000000   Inserted batch 640000/1000000   Inserted batch 650000/1000000   Inserted batch 660000/1000000   Inserted batch 670000/1000000   Inserted batch 680000/1000000   Inserted batch 690000/1000000   Inserted batch 700000/1000000   Inserted batch 710000/1000000   Inserted batch 720000/1000000   Inserted batch 730000/1000000   Inserted batch 740000/1000000   Inserted batch 750000/1000000   Inserted batch 760000/1000000   Inserted batch 770000/1000000   Inserted batch 780000/1000000   Inserted batch 790000/1000000   Inserted batch 800000/1000000   Inserted batch 810000/1000000   Inserted batch 820000/1000000   Inserted batch 830000/1000000   Inserted batch 840000/1000000   Inserted batch 850000/1000000   Inserted batch 860000/1000000   Inserted batch 870000/1000000   Inserted batch 880000/1000000   Inserted batch 890000/1000000   Inserted batch 900000/1000000   Inserted batch 910000/1000000   Inserted batch 920000/1000000   Inserted batch 930000/1000000   Inserted batch 940000/1000000   Inserted batch 950000/1000000   Inserted batch 960000/1000000   Inserted batch 970000/1000000   Inserted batch 980000/1000000   Inserted batch 990000/1000000   Inserted batch 1000000/1000000
‚úÖ Pgvector: Insertion complete.
üî® Pgvector: Building hnsw index...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=1.0000, Latency_p50=8.20ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=8.12ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=8.18ms
  Applying tuned parameters for sift1m
  Skipping HNSW_Cosine: Metric mismatch
    Results: pgvector_sift1m (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9375 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 8.1672 ¬± 0.0413    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 10.7669 ¬± 0.0965   ‚îÇ
‚îÇ QPS              ‚îÇ 126.3492 ¬± 1.0896  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 3000.7110 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/pgvector/sift1m_pgvector_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T20:23:54Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container pgvector_benchmark  Stopping
 Container pgvector_benchmark  Stopped
 Container pgvector_benchmark  Removing
 Container pgvector_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T20:23:59Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container pgvector_benchmark  Creating
 Container pgvector_benchmark  Created
 Container pgvector_benchmark  Starting
 Container pgvector_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: pgvector
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: pgvector on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Pgvector: Inserting 1000000 vectors in batches...
   Inserted batch 10000/1000000   Inserted batch 20000/1000000   Inserted batch 30000/1000000   Inserted batch 40000/1000000   Inserted batch 50000/1000000   Inserted batch 60000/1000000   Inserted batch 70000/1000000   Inserted batch 80000/1000000   Inserted batch 90000/1000000   Inserted batch 100000/1000000   Inserted batch 110000/1000000   Inserted batch 120000/1000000   Inserted batch 130000/1000000   Inserted batch 140000/1000000   Inserted batch 150000/1000000   Inserted batch 160000/1000000   Inserted batch 170000/1000000   Inserted batch 180000/1000000   Inserted batch 190000/1000000   Inserted batch 200000/1000000   Inserted batch 210000/1000000   Inserted batch 220000/1000000   Inserted batch 230000/1000000   Inserted batch 240000/1000000   Inserted batch 250000/1000000   Inserted batch 260000/1000000   Inserted batch 270000/1000000   Inserted batch 280000/1000000   Inserted batch 290000/1000000   Inserted batch 300000/1000000   Inserted batch 310000/1000000   Inserted batch 320000/1000000   Inserted batch 330000/1000000   Inserted batch 340000/1000000   Inserted batch 350000/1000000   Inserted batch 360000/1000000   Inserted batch 370000/1000000   Inserted batch 380000/1000000   Inserted batch 390000/1000000   Inserted batch 400000/1000000   Inserted batch 410000/1000000   Inserted batch 420000/1000000   Inserted batch 430000/1000000   Inserted batch 440000/1000000   Inserted batch 450000/1000000   Inserted batch 460000/1000000   Inserted batch 470000/1000000   Inserted batch 480000/1000000   Inserted batch 490000/1000000   Inserted batch 500000/1000000   Inserted batch 510000/1000000   Inserted batch 520000/1000000   Inserted batch 530000/1000000   Inserted batch 540000/1000000   Inserted batch 550000/1000000   Inserted batch 560000/1000000   Inserted batch 570000/1000000   Inserted batch 580000/1000000   Inserted batch 590000/1000000   Inserted batch 600000/1000000   Inserted batch 610000/1000000   Inserted batch 620000/1000000   Inserted batch 630000/1000000   Inserted batch 640000/1000000   Inserted batch 650000/1000000   Inserted batch 660000/1000000   Inserted batch 670000/1000000   Inserted batch 680000/1000000   Inserted batch 690000/1000000   Inserted batch 700000/1000000   Inserted batch 710000/1000000   Inserted batch 720000/1000000   Inserted batch 730000/1000000   Inserted batch 740000/1000000   Inserted batch 750000/1000000   Inserted batch 760000/1000000   Inserted batch 770000/1000000   Inserted batch 780000/1000000   Inserted batch 790000/1000000   Inserted batch 800000/1000000   Inserted batch 810000/1000000   Inserted batch 820000/1000000   Inserted batch 830000/1000000   Inserted batch 840000/1000000   Inserted batch 850000/1000000   Inserted batch 860000/1000000   Inserted batch 870000/1000000   Inserted batch 880000/1000000   Inserted batch 890000/1000000   Inserted batch 900000/1000000   Inserted batch 910000/1000000   Inserted batch 920000/1000000   Inserted batch 930000/1000000   Inserted batch 940000/1000000   Inserted batch 950000/1000000   Inserted batch 960000/1000000   Inserted batch 970000/1000000   Inserted batch 980000/1000000   Inserted batch 990000/1000000   Inserted batch 1000000/1000000
‚úÖ Pgvector: Insertion complete.
üî® Pgvector: Building hnsw index...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=0.9999, Latency_p50=5.86ms
    Run 2/3: Searching...    Run 2: Recall@10=0.9999, Latency_p50=5.39ms
    Run 3/3: Searching...    Run 3: Recall@10=0.9999, Latency_p50=5.61ms
  Applying tuned parameters for deep1m
  Skipping HNSW_Cosine: Metric mismatch
    Results: pgvector_deep1m (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.6384 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.6217 ¬± 0.2365    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 14.0890 ¬± 10.7333  ‚îÇ
‚îÇ QPS              ‚îÇ 167.9369 ¬± 27.6218 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 2100.8965 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/pgvector/deep1m_pgvector_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T21:03:22Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container pgvector_benchmark  Stopping
 Container pgvector_benchmark  Stopped
 Container pgvector_benchmark  Removing
 Container pgvector_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T21:03:27Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container pgvector_benchmark  Creating
 Container pgvector_benchmark  Created
 Container pgvector_benchmark  Starting
 Container pgvector_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: pgvector
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: pgvector on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Pgvector: Inserting 1000000 vectors in batches...
   Inserted batch 10000/1000000   Inserted batch 20000/1000000   Inserted batch 30000/1000000   Inserted batch 40000/1000000   Inserted batch 50000/1000000   Inserted batch 60000/1000000   Inserted batch 70000/1000000   Inserted batch 80000/1000000   Inserted batch 90000/1000000   Inserted batch 100000/1000000   Inserted batch 110000/1000000   Inserted batch 120000/1000000   Inserted batch 130000/1000000   Inserted batch 140000/1000000   Inserted batch 150000/1000000   Inserted batch 160000/1000000   Inserted batch 170000/1000000   Inserted batch 180000/1000000   Inserted batch 190000/1000000   Inserted batch 200000/1000000   Inserted batch 210000/1000000   Inserted batch 220000/1000000   Inserted batch 230000/1000000   Inserted batch 240000/1000000   Inserted batch 250000/1000000   Inserted batch 260000/1000000   Inserted batch 270000/1000000   Inserted batch 280000/1000000   Inserted batch 290000/1000000   Inserted batch 300000/1000000   Inserted batch 310000/1000000   Inserted batch 320000/1000000   Inserted batch 330000/1000000   Inserted batch 340000/1000000   Inserted batch 350000/1000000   Inserted batch 360000/1000000   Inserted batch 370000/1000000   Inserted batch 380000/1000000   Inserted batch 390000/1000000   Inserted batch 400000/1000000   Inserted batch 410000/1000000   Inserted batch 420000/1000000   Inserted batch 430000/1000000   Inserted batch 440000/1000000   Inserted batch 450000/1000000   Inserted batch 460000/1000000   Inserted batch 470000/1000000   Inserted batch 480000/1000000   Inserted batch 490000/1000000   Inserted batch 500000/1000000   Inserted batch 510000/1000000   Inserted batch 520000/1000000   Inserted batch 530000/1000000   Inserted batch 540000/1000000   Inserted batch 550000/1000000   Inserted batch 560000/1000000   Inserted batch 570000/1000000   Inserted batch 580000/1000000   Inserted batch 590000/1000000   Inserted batch 600000/1000000   Inserted batch 610000/1000000   Inserted batch 620000/1000000   Inserted batch 630000/1000000   Inserted batch 640000/1000000   Inserted batch 650000/1000000   Inserted batch 660000/1000000   Inserted batch 670000/1000000   Inserted batch 680000/1000000   Inserted batch 690000/1000000   Inserted batch 700000/1000000   Inserted batch 710000/1000000   Inserted batch 720000/1000000   Inserted batch 730000/1000000   Inserted batch 740000/1000000   Inserted batch 750000/1000000   Inserted batch 760000/1000000   Inserted batch 770000/1000000   Inserted batch 780000/1000000   Inserted batch 790000/1000000   Inserted batch 800000/1000000   Inserted batch 810000/1000000   Inserted batch 820000/1000000   Inserted batch 830000/1000000   Inserted batch 840000/1000000   Inserted batch 850000/1000000   Inserted batch 860000/1000000   Inserted batch 870000/1000000   Inserted batch 880000/1000000   Inserted batch 890000/1000000   Inserted batch 900000/1000000   Inserted batch 910000/1000000   Inserted batch 920000/1000000   Inserted batch 930000/1000000   Inserted batch 940000/1000000   Inserted batch 950000/1000000   Inserted batch 960000/1000000   Inserted batch 970000/1000000   Inserted batch 980000/1000000   Inserted batch 990000/1000000   Inserted batch 1000000/1000000
‚úÖ Pgvector: Insertion complete.
üî® Pgvector: Building hnsw index...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=0.9705, Latency_p50=7.04ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=0.9705, Latency_p50=5.07ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=0.9705, Latency_p50=4.27ms
  Applying tuned parameters for random
  Skipping HNSW_Cosine: Metric mismatch
    Results: pgvector_random (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9705 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.1438 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.4598 ¬± 1.4268    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 10.3368 ¬± 5.1442   ‚îÇ
‚îÇ QPS              ‚îÇ 183.3864 ¬± 48.5376 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 2700.3112 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/pgvector/random_pgvector_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T21:53:32Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container pgvector_benchmark  Stopping
 Container pgvector_benchmark  Stopped
 Container pgvector_benchmark  Removing
 Container pgvector_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T21:53:38Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container pgvector_benchmark  Creating
 Container pgvector_benchmark  Created
 Container pgvector_benchmark  Starting
 Container pgvector_benchmark  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: pgvector
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: pgvector on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Pgvector: Inserting 100000 vectors in batches...
   Inserted batch 10000/100000   Inserted batch 20000/100000   Inserted batch 30000/100000   Inserted batch 40000/100000   Inserted batch 50000/100000   Inserted batch 60000/100000   Inserted batch 70000/100000   Inserted batch 80000/100000   Inserted batch 90000/100000   Inserted batch 100000/100000
‚úÖ Pgvector: Insertion complete.
‚ö° High dimensionality (768d) detected. Boosting HNSW parameters...
üî® Pgvector: Building hnsw index...
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 1: Recall@10=1.0000, Latency_p50=9.76ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=9.46ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=9.72ms
   Results: pgvector_msmarco (runs=3)    
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9689 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 9.6473 ¬± 0.1590    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 13.0419 ¬± 0.4647   ‚îÇ
‚îÇ QPS              ‚îÇ 103.5780 ¬± 1.6664  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 1711.5701 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/pgvector/msmarco_pgvector_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T22:23:59Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container pgvector_benchmark  Stopping
 Container pgvector_benchmark  Stopped
 Container pgvector_benchmark  Removing
 Container pgvector_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T22:24:04Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container pgvector_benchmark  Creating
 Container pgvector_benchmark  Created
 Container pgvector_benchmark  Starting
 Container pgvector_benchmark  Started
üßπ Cleaning up workspace...

============================================================
 PREPARING BENCHMARK FOR: MILVUS
============================================================
üöÄ Starting milvus...
‚è≥ Polling Milvus port 19530...
‚úÖ Milvus is ready!

‚ñ∂Ô∏è  Running: milvus on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database milvus --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting milvus...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Polling Milvus port 19530...
‚úÖ Milvus is ready!

‚ñ∂Ô∏è  Running: milvus on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database milvus --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting milvus...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Polling Milvus port 19530...
‚úÖ Milvus is ready!

‚ñ∂Ô∏è  Running: milvus on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database milvus --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting milvus...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Polling Milvus port 19530...
‚úÖ Milvus is ready!

‚ñ∂Ô∏è  Running: milvus on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database milvus --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting milvus...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Polling Milvus port 19530...
‚úÖ Milvus is ready!

‚ñ∂Ô∏è  Running: milvus on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database milvus --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
üõë Stopping milvus...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...

============================================================
 PREPARING BENCHMARK FOR: QDRANT
============================================================
üöÄ Starting qdrant...
‚è≥ Waiting 30s for qdrant...

‚ñ∂Ô∏è  Running: qdrant on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database qdrant --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting qdrant...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for qdrant...

‚ñ∂Ô∏è  Running: qdrant on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database qdrant --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting qdrant...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for qdrant...

‚ñ∂Ô∏è  Running: qdrant on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database qdrant --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting qdrant...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for qdrant...

‚ñ∂Ô∏è  Running: qdrant on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database qdrant --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting qdrant...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for qdrant...

‚ñ∂Ô∏è  Running: qdrant on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database qdrant --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
üõë Stopping qdrant...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...

============================================================
 PREPARING BENCHMARK FOR: WEAVIATE
============================================================
üöÄ Starting weaviate...
‚è≥ Waiting 30s for weaviate...

‚ñ∂Ô∏è  Running: weaviate on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database weaviate --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting weaviate...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for weaviate...

‚ñ∂Ô∏è  Running: weaviate on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database weaviate --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting weaviate...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for weaviate...

‚ñ∂Ô∏è  Running: weaviate on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database weaviate --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting weaviate...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for weaviate...

‚ñ∂Ô∏è  Running: weaviate on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database weaviate --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting weaviate...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for weaviate...

‚ñ∂Ô∏è  Running: weaviate on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database weaviate --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
üõë Stopping weaviate...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...

============================================================
 PREPARING BENCHMARK FOR: PGVECTOR
============================================================
üöÄ Starting pgvector...
‚è≥ Waiting 30s for pgvector...

‚ñ∂Ô∏è  Running: pgvector on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database pgvector --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting pgvector...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for pgvector...

‚ñ∂Ô∏è  Running: pgvector on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database pgvector --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting pgvector...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for pgvector...

‚ñ∂Ô∏è  Running: pgvector on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database pgvector --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting pgvector...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for pgvector...

‚ñ∂Ô∏è  Running: pgvector on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database pgvector --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting pgvector...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for pgvector...

‚ñ∂Ô∏è  Running: pgvector on glove...
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: pgvector
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: pgvector on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Pgvector: Inserting 390000 vectors in batches...
   Inserted batch 10000/390000   Inserted batch 20000/390000   Inserted batch 30000/390000   Inserted batch 40000/390000   Inserted batch 50000/390000   Inserted batch 60000/390000   Inserted batch 70000/390000   Inserted batch 80000/390000   Inserted batch 90000/390000   Inserted batch 100000/390000   Inserted batch 110000/390000   Inserted batch 120000/390000   Inserted batch 130000/390000   Inserted batch 140000/390000   Inserted batch 150000/390000   Inserted batch 160000/390000   Inserted batch 170000/390000   Inserted batch 180000/390000   Inserted batch 190000/390000   Inserted batch 200000/390000   Inserted batch 210000/390000   Inserted batch 220000/390000   Inserted batch 230000/390000   Inserted batch 240000/390000   Inserted batch 250000/390000   Inserted batch 260000/390000   Inserted batch 270000/390000   Inserted batch 280000/390000   Inserted batch 290000/390000   Inserted batch 300000/390000   Inserted batch 310000/390000   Inserted batch 320000/390000   Inserted batch 330000/390000   Inserted batch 340000/390000   Inserted batch 350000/390000   Inserted batch 360000/390000   Inserted batch 370000/390000   Inserted batch 380000/390000   Inserted batch 390000/390000
‚úÖ Pgvector: Insertion complete.
üî® Pgvector: Building hnsw index...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=1.0000, Latency_p50=5.62ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=1.0000, Latency_p50=5.65ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=1.0000, Latency_p50=5.71ms
    Results: pgvector_glove (runs=3)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9531 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.6575 ¬± 0.0470    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 7.7652 ¬± 0.3711    ‚îÇ
‚îÇ QPS              ‚îÇ 183.0383 ¬± 2.1779  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 1409.5815 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/pgvector/glove_pgvector_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T22:58:49Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/pgvector-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container pgvector_benchmark  Stopping
 Container pgvector_benchmark  Stopped
 Container pgvector_benchmark  Removing
 Container pgvector_benchmark  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T22:58:50Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container chroma-server  Creating
 Container chroma-server  Created
 Container chroma-server  Starting
 Container chroma-server  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: chroma
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: chroma on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Chroma: Inserting 1000000 vectors in batches...
   Processed 2000/1000000 vectors...   Processed 12000/1000000 vectors...   Processed 22000/1000000 vectors...   Processed 32000/1000000 vectors...   Processed 42000/1000000 vectors...   Processed 52000/1000000 vectors...   Processed 62000/1000000 vectors...   Processed 72000/1000000 vectors...   Processed 82000/1000000 vectors...   Processed 92000/1000000 vectors...   Processed 102000/1000000 vectors...   Processed 112000/1000000 vectors...   Processed 122000/1000000 vectors...   Processed 132000/1000000 vectors...   Processed 142000/1000000 vectors...   Processed 152000/1000000 vectors...   Processed 162000/1000000 vectors...   Processed 172000/1000000 vectors...   Processed 182000/1000000 vectors...   Processed 192000/1000000 vectors...   Processed 202000/1000000 vectors...   Processed 212000/1000000 vectors...   Processed 222000/1000000 vectors...   Processed 232000/1000000 vectors...   Processed 242000/1000000 vectors...   Processed 252000/1000000 vectors...   Processed 262000/1000000 vectors...   Processed 272000/1000000 vectors...   Processed 282000/1000000 vectors...   Processed 292000/1000000 vectors...   Processed 302000/1000000 vectors...   Processed 312000/1000000 vectors...   Processed 322000/1000000 vectors...   Processed 332000/1000000 vectors...   Processed 342000/1000000 vectors...   Processed 352000/1000000 vectors...   Processed 362000/1000000 vectors...   Processed 372000/1000000 vectors...   Processed 382000/1000000 vectors...   Processed 392000/1000000 vectors...   Processed 402000/1000000 vectors...   Processed 412000/1000000 vectors...   Processed 422000/1000000 vectors...   Processed 432000/1000000 vectors...   Processed 442000/1000000 vectors...   Processed 452000/1000000 vectors...   Processed 462000/1000000 vectors...   Processed 472000/1000000 vectors...   Processed 482000/1000000 vectors...   Processed 492000/1000000 vectors...   Processed 502000/1000000 vectors...   Processed 512000/1000000 vectors...   Processed 522000/1000000 vectors...   Processed 532000/1000000 vectors...   Processed 542000/1000000 vectors...   Processed 552000/1000000 vectors...   Processed 562000/1000000 vectors...   Processed 572000/1000000 vectors...   Processed 582000/1000000 vectors...   Processed 592000/1000000 vectors...   Processed 602000/1000000 vectors...   Processed 612000/1000000 vectors...   Processed 622000/1000000 vectors...   Processed 632000/1000000 vectors...   Processed 642000/1000000 vectors...   Processed 652000/1000000 vectors...   Processed 662000/1000000 vectors...   Processed 672000/1000000 vectors...   Processed 682000/1000000 vectors...   Processed 692000/1000000 vectors...   Processed 702000/1000000 vectors...   Processed 712000/1000000 vectors...   Processed 722000/1000000 vectors...   Processed 732000/1000000 vectors...   Processed 742000/1000000 vectors...   Processed 752000/1000000 vectors...   Processed 762000/1000000 vectors...   Processed 772000/1000000 vectors...   Processed 782000/1000000 vectors...   Processed 792000/1000000 vectors...   Processed 802000/1000000 vectors...   Processed 812000/1000000 vectors...   Processed 822000/1000000 vectors...   Processed 832000/1000000 vectors...   Processed 842000/1000000 vectors...   Processed 852000/1000000 vectors...   Processed 862000/1000000 vectors...   Processed 872000/1000000 vectors...   Processed 882000/1000000 vectors...   Processed 892000/1000000 vectors...   Processed 902000/1000000 vectors...   Processed 912000/1000000 vectors...   Processed 922000/1000000 vectors...   Processed 932000/1000000 vectors...   Processed 942000/1000000 vectors...   Processed 952000/1000000 vectors...   Processed 962000/1000000 vectors...   Processed 972000/1000000 vectors...   Processed 982000/1000000 vectors...   Processed 992000/1000000 vectors...
‚úÖ Chroma: Insertion complete.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...Search run 0 failed: Changing the distance function of a collection once it is created is not supported currently.
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/chroma_adapter.py", line 193, in search
    self._collection.modify(metadata=current_meta)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py", line 261, in modify
    self._validate_modify_request(metadata)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py", line 542, in _validate_modify_request
    raise ValueError(
ValueError: Changing the distance function of a collection once it is created is not supported currently.
    Run 1 Failed: Changing the distance function of a collection once it is created is not supported currently.
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=6.05ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=6.39ms
  Applying tuned parameters for sift1m
  Skipping HNSW_Cosine: Metric mismatch
     Results: chroma_sift1m (runs=2)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9235 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 6.2192 ¬± 0.2440    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 10.2961 ¬± 2.8862   ‚îÇ
‚îÇ QPS              ‚îÇ 153.8907 ¬± 12.9439 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 1113.5193 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/chroma/sift1m_chroma_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T23:21:53Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container chroma-server  Stopping
 Container chroma-server  Stopped
 Container chroma-server  Removing
 Container chroma-server  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T23:21:59Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container chroma-server  Creating
 Container chroma-server  Created
 Container chroma-server  Starting
 Container chroma-server  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: chroma
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: chroma on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Chroma: Inserting 1000000 vectors in batches...
   Processed 2000/1000000 vectors...   Processed 12000/1000000 vectors...   Processed 22000/1000000 vectors...   Processed 32000/1000000 vectors...   Processed 42000/1000000 vectors...   Processed 52000/1000000 vectors...   Processed 62000/1000000 vectors...   Processed 72000/1000000 vectors...   Processed 82000/1000000 vectors...   Processed 92000/1000000 vectors...   Processed 102000/1000000 vectors...   Processed 112000/1000000 vectors...   Processed 122000/1000000 vectors...   Processed 132000/1000000 vectors...   Processed 142000/1000000 vectors...   Processed 152000/1000000 vectors...   Processed 162000/1000000 vectors...   Processed 172000/1000000 vectors...   Processed 182000/1000000 vectors...   Processed 192000/1000000 vectors...   Processed 202000/1000000 vectors...   Processed 212000/1000000 vectors...   Processed 222000/1000000 vectors...   Processed 232000/1000000 vectors...   Processed 242000/1000000 vectors...   Processed 252000/1000000 vectors...   Processed 262000/1000000 vectors...   Processed 272000/1000000 vectors...   Processed 282000/1000000 vectors...   Processed 292000/1000000 vectors...   Processed 302000/1000000 vectors...   Processed 312000/1000000 vectors...   Processed 322000/1000000 vectors...   Processed 332000/1000000 vectors...   Processed 342000/1000000 vectors...   Processed 352000/1000000 vectors...   Processed 362000/1000000 vectors...   Processed 372000/1000000 vectors...   Processed 382000/1000000 vectors...   Processed 392000/1000000 vectors...   Processed 402000/1000000 vectors...   Processed 412000/1000000 vectors...   Processed 422000/1000000 vectors...   Processed 432000/1000000 vectors...   Processed 442000/1000000 vectors...   Processed 452000/1000000 vectors...   Processed 462000/1000000 vectors...   Processed 472000/1000000 vectors...   Processed 482000/1000000 vectors...   Processed 492000/1000000 vectors...   Processed 502000/1000000 vectors...   Processed 512000/1000000 vectors...   Processed 522000/1000000 vectors...   Processed 532000/1000000 vectors...   Processed 542000/1000000 vectors...   Processed 552000/1000000 vectors...   Processed 562000/1000000 vectors...   Processed 572000/1000000 vectors...   Processed 582000/1000000 vectors...   Processed 592000/1000000 vectors...   Processed 602000/1000000 vectors...   Processed 612000/1000000 vectors...   Processed 622000/1000000 vectors...   Processed 632000/1000000 vectors...   Processed 642000/1000000 vectors...   Processed 652000/1000000 vectors...   Processed 662000/1000000 vectors...   Processed 672000/1000000 vectors...   Processed 682000/1000000 vectors...   Processed 692000/1000000 vectors...   Processed 702000/1000000 vectors...   Processed 712000/1000000 vectors...   Processed 722000/1000000 vectors...   Processed 732000/1000000 vectors...   Processed 742000/1000000 vectors...   Processed 752000/1000000 vectors...   Processed 762000/1000000 vectors...   Processed 772000/1000000 vectors...   Processed 782000/1000000 vectors...   Processed 792000/1000000 vectors...   Processed 802000/1000000 vectors...   Processed 812000/1000000 vectors...   Processed 822000/1000000 vectors...   Processed 832000/1000000 vectors...   Processed 842000/1000000 vectors...   Processed 852000/1000000 vectors...   Processed 862000/1000000 vectors...   Processed 872000/1000000 vectors...   Processed 882000/1000000 vectors...   Processed 892000/1000000 vectors...   Processed 902000/1000000 vectors...   Processed 912000/1000000 vectors...   Processed 922000/1000000 vectors...   Processed 932000/1000000 vectors...   Processed 942000/1000000 vectors...   Processed 952000/1000000 vectors...   Processed 962000/1000000 vectors...   Processed 972000/1000000 vectors...   Processed 982000/1000000 vectors...   Processed 992000/1000000 vectors...
‚úÖ Chroma: Insertion complete.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...Search run 0 failed: Changing the distance function of a collection once it is created is not supported currently.
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/chroma_adapter.py", line 193, in search
    self._collection.modify(metadata=current_meta)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py", line 261, in modify
    self._validate_modify_request(metadata)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py", line 542, in _validate_modify_request
    raise ValueError(
ValueError: Changing the distance function of a collection once it is created is not supported currently.
    Run 1 Failed: Changing the distance function of a collection once it is created is not supported currently.
    Run 2/3: Searching...    Run 2: Recall@10=0.9999, Latency_p50=5.97ms
    Run 3/3: Searching...    Run 3: Recall@10=0.9999, Latency_p50=5.95ms
  Applying tuned parameters for deep1m
  Skipping HNSW_Cosine: Metric mismatch
     Results: chroma_deep1m (runs=2)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9097 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 0.9999 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.9611 ¬± 0.0147    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 8.9060 ¬± 1.0975    ‚îÇ
‚îÇ QPS              ‚îÇ 163.3825 ¬± 1.3646  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 952.3379 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/chroma/deep1m_chroma_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2025-12-31T23:41:10Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container chroma-server  Stopping
 Container chroma-server  Stopped
 Container chroma-server  Removing
 Container chroma-server  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2025-12-31T23:41:16Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container chroma-server  Creating
 Container chroma-server  Created
 Container chroma-server  Starting
 Container chroma-server  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: chroma
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: chroma on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: HNSW_L2
    Building Index (Once)...
üöÄ Chroma: Inserting 1000000 vectors in batches...
   Processed 2000/1000000 vectors...   Processed 12000/1000000 vectors...   Processed 22000/1000000 vectors...   Processed 32000/1000000 vectors...   Processed 42000/1000000 vectors...   Processed 52000/1000000 vectors...   Processed 62000/1000000 vectors...   Processed 72000/1000000 vectors...   Processed 82000/1000000 vectors...   Processed 92000/1000000 vectors...   Processed 102000/1000000 vectors...   Processed 112000/1000000 vectors...   Processed 122000/1000000 vectors...   Processed 132000/1000000 vectors...   Processed 142000/1000000 vectors...   Processed 152000/1000000 vectors...   Processed 162000/1000000 vectors...   Processed 172000/1000000 vectors...   Processed 182000/1000000 vectors...   Processed 192000/1000000 vectors...   Processed 202000/1000000 vectors...   Processed 212000/1000000 vectors...   Processed 222000/1000000 vectors...   Processed 232000/1000000 vectors...   Processed 242000/1000000 vectors...   Processed 252000/1000000 vectors...   Processed 262000/1000000 vectors...   Processed 272000/1000000 vectors...   Processed 282000/1000000 vectors...   Processed 292000/1000000 vectors...   Processed 302000/1000000 vectors...   Processed 312000/1000000 vectors...   Processed 322000/1000000 vectors...   Processed 332000/1000000 vectors...   Processed 342000/1000000 vectors...   Processed 352000/1000000 vectors...   Processed 362000/1000000 vectors...   Processed 372000/1000000 vectors...   Processed 382000/1000000 vectors...   Processed 392000/1000000 vectors...   Processed 402000/1000000 vectors...   Processed 412000/1000000 vectors...   Processed 422000/1000000 vectors...   Processed 432000/1000000 vectors...   Processed 442000/1000000 vectors...   Processed 452000/1000000 vectors...   Processed 462000/1000000 vectors...   Processed 472000/1000000 vectors...   Processed 482000/1000000 vectors...   Processed 492000/1000000 vectors...   Processed 502000/1000000 vectors...   Processed 512000/1000000 vectors...   Processed 522000/1000000 vectors...   Processed 532000/1000000 vectors...   Processed 542000/1000000 vectors...   Processed 552000/1000000 vectors...   Processed 562000/1000000 vectors...   Processed 572000/1000000 vectors...   Processed 582000/1000000 vectors...   Processed 592000/1000000 vectors...   Processed 602000/1000000 vectors...   Processed 612000/1000000 vectors...   Processed 622000/1000000 vectors...   Processed 632000/1000000 vectors...   Processed 642000/1000000 vectors...   Processed 652000/1000000 vectors...   Processed 662000/1000000 vectors...   Processed 672000/1000000 vectors...   Processed 682000/1000000 vectors...   Processed 692000/1000000 vectors...   Processed 702000/1000000 vectors...   Processed 712000/1000000 vectors...   Processed 722000/1000000 vectors...   Processed 732000/1000000 vectors...   Processed 742000/1000000 vectors...   Processed 752000/1000000 vectors...   Processed 762000/1000000 vectors...   Processed 772000/1000000 vectors...   Processed 782000/1000000 vectors...   Processed 792000/1000000 vectors...   Processed 802000/1000000 vectors...   Processed 812000/1000000 vectors...   Processed 822000/1000000 vectors...   Processed 832000/1000000 vectors...   Processed 842000/1000000 vectors...   Processed 852000/1000000 vectors...   Processed 862000/1000000 vectors...   Processed 872000/1000000 vectors...   Processed 882000/1000000 vectors...   Processed 892000/1000000 vectors...   Processed 902000/1000000 vectors...   Processed 912000/1000000 vectors...   Processed 922000/1000000 vectors...   Processed 932000/1000000 vectors...   Processed 942000/1000000 vectors...   Processed 952000/1000000 vectors...   Processed 962000/1000000 vectors...   Processed 972000/1000000 vectors...   Processed 982000/1000000 vectors...   Processed 992000/1000000 vectors...
‚úÖ Chroma: Insertion complete.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...Search run 0 failed: Changing the distance function of a collection once it is created is not supported currently.
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/chroma_adapter.py", line 193, in search
    self._collection.modify(metadata=current_meta)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py", line 261, in modify
    self._validate_modify_request(metadata)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py", line 542, in _validate_modify_request
    raise ValueError(
ValueError: Changing the distance function of a collection once it is created is not supported currently.
    Run 1 Failed: Changing the distance function of a collection once it is created is not supported currently.
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=0.9979, Latency_p50=6.39ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=0.9979, Latency_p50=6.15ms
  Applying tuned parameters for random
  Skipping HNSW_Cosine: Metric mismatch
     Results: chroma_random (runs=2)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9979 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.1970 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 6.2699 ¬± 0.1671    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 8.3624 ¬± 1.0146    ‚îÇ
‚îÇ QPS              ‚îÇ 157.0393 ¬± 5.8595  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 1111.6484 ¬± 0.0000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/chroma/random_chroma_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2026-01-01T00:04:13Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container chroma-server  Stopping
 Container chroma-server  Stopped
 Container chroma-server  Removing
 Container chroma-server  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2026-01-01T00:04:19Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container chroma-server  Creating
 Container chroma-server  Created
 Container chroma-server  Starting
 Container chroma-server  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: chroma
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: chroma on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Chroma: Inserting 100000 vectors in batches...
   Processed 2000/100000 vectors...   Processed 12000/100000 vectors...   Processed 22000/100000 vectors...   Processed 32000/100000 vectors...   Processed 42000/100000 vectors...   Processed 52000/100000 vectors...   Processed 62000/100000 vectors...   Processed 72000/100000 vectors...   Processed 82000/100000 vectors...   Processed 92000/100000 vectors...
‚úÖ Chroma: Insertion complete.
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...Search run 0 failed: Changing the distance function of a collection once it is created is not supported currently.
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/chroma_adapter.py", line 193, in search
    self._collection.modify(metadata=current_meta)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py", line 261, in modify
    self._validate_modify_request(metadata)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py", line 542, in _validate_modify_request
    raise ValueError(
ValueError: Changing the distance function of a collection once it is created is not supported currently.
    Run 1 Failed: Changing the distance function of a collection once it is created is not supported currently.
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=7.39ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=7.44ms
    Results: chroma_msmarco (runs=2)     
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9390 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 7.4153 ¬± 0.0420    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 8.9795 ¬± 0.1178    ‚îÇ
‚îÇ QPS              ‚îÇ 132.8464 ¬± 0.6717  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 179.7084 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/chroma/msmarco_chroma_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2026-01-01T00:08:53Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container chroma-server  Stopping
 Container chroma-server  Stopped
 Container chroma-server  Removing
 Container chroma-server  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
time="2026-01-01T00:08:59Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Network ragdbeval_default  Creating
 Network ragdbeval_default  Created
 Container chroma-server  Creating
 Container chroma-server  Created
 Container chroma-server  Starting
 Container chroma-server  Started
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: chroma
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: chroma on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping HNSW_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: HNSW_Cosine
    Building Index (Once)...
üöÄ Chroma: Inserting 390000 vectors in batches...
   Processed 2000/390000 vectors...   Processed 12000/390000 vectors...   Processed 22000/390000 vectors...   Processed 32000/390000 vectors...   Processed 42000/390000 vectors...   Processed 52000/390000 vectors...   Processed 62000/390000 vectors...   Processed 72000/390000 vectors...   Processed 82000/390000 vectors...   Processed 92000/390000 vectors...   Processed 102000/390000 vectors...   Processed 112000/390000 vectors...   Processed 122000/390000 vectors...   Processed 132000/390000 vectors...   Processed 142000/390000 vectors...   Processed 152000/390000 vectors...   Processed 162000/390000 vectors...   Processed 172000/390000 vectors...   Processed 182000/390000 vectors...   Processed 192000/390000 vectors...   Processed 202000/390000 vectors...   Processed 212000/390000 vectors...   Processed 222000/390000 vectors...   Processed 232000/390000 vectors...   Processed 242000/390000 vectors...   Processed 252000/390000 vectors...   Processed 262000/390000 vectors...   Processed 272000/390000 vectors...   Processed 282000/390000 vectors...   Processed 292000/390000 vectors...   Processed 302000/390000 vectors...   Processed 312000/390000 vectors...   Processed 322000/390000 vectors...   Processed 332000/390000 vectors...   Processed 342000/390000 vectors...   Processed 352000/390000 vectors...   Processed 362000/390000 vectors...   Processed 372000/390000 vectors...   Processed 382000/390000 vectors...
‚úÖ Chroma: Insertion complete.
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...Search run 0 failed: Changing the distance function of a collection once it is created is not supported currently.
Traceback (most recent call last):
  File "/home/ashenrashmike2000/RAGdbEval/src/benchmark/runner.py", line 333, in _run_single_benchmark
    indices, distances, latencies = db.search(queries, 100, final_search_params)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ashenrashmike2000/RAGdbEval/src/databases/chroma_adapter.py", line 193, in search
    self._collection.modify(metadata=current_meta)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py", line 261, in modify
    self._validate_modify_request(metadata)
  File "/home/ashenrashmike2000/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py", line 542, in _validate_modify_request
    raise ValueError(
ValueError: Changing the distance function of a collection once it is created is not supported currently.
    Run 1 Failed: Changing the distance function of a collection once it is created is not supported currently.
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=0.9998, Latency_p50=5.74ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=0.9998, Latency_p50=5.70ms
     Results: chroma_glove (runs=2)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std) ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.9998 ¬± 0.0000    ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.9027 ¬± 0.0000    ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000    ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 5.7185 ¬± 0.0325    ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 7.3688 ¬± 0.1436    ‚îÇ
‚îÇ QPS              ‚îÇ 173.1773 ¬± 1.2219  ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 298.5866 ¬± 0.0000  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/chroma/glove_chroma_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
time="2026-01-01T00:24:34Z" level=warning msg="/home/ashenrashmike2000/RAGdbEval/chroma-docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
 Container chroma-server  Stopping
 Container chroma-server  Stopped
 Container chroma-server  Removing
 Container chroma-server  Removed
 Network ragdbeval_default  Removing
 Network ragdbeval_default  Removed
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: lancedb
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: lancedb on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
Benchmark failed for lancedb: type object 'IndexType' has no attribute 'IVF_PQ'
Error: type object 'IndexType' has no attribute 'IVF_PQ'
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: lancedb
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: lancedb on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
Benchmark failed for lancedb: type object 'IndexType' has no attribute 'IVF_PQ'
Error: type object 'IndexType' has no attribute 'IVF_PQ'
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: lancedb
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: lancedb on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
Benchmark failed for lancedb: type object 'IndexType' has no attribute 'IVF_PQ'
Error: type object 'IndexType' has no attribute 'IVF_PQ'
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: lancedb
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: lancedb on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
Benchmark failed for lancedb: type object 'IndexType' has no attribute 'IVF_PQ'
Error: type object 'IndexType' has no attribute 'IVF_PQ'
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: lancedb
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: lancedb on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
Benchmark failed for lancedb: type object 'IndexType' has no attribute 'IVF_PQ'
Error: type object 'IndexType' has no attribute 'IVF_PQ'
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
‚ö†Ô∏è No valid results to plot.
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: faiss
Datasets: sift1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: sift1m

Benchmarking: faiss on sift1m
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for sift1m

  Index: IVF1024_L2
    Building Index (Once)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=1.0000, Latency_p50=0.58ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=0.57ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=0.66ms
  Applying tuned parameters for sift1m
  Skipping IVF1024_IP: Metric mismatch
      Results: faiss_sift1m (runs=3)       
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std)   ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000      ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.7543 ¬± 0.0000      ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000      ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 0.6050 ¬± 0.0495      ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 1.4882 ¬± 0.8543      ‚îÇ
‚îÇ QPS              ‚îÇ 1493.8975 ¬± 275.5710 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 11.3099 ¬± 0.0000     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/faiss/sift1m_faiss_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: faiss
Datasets: deep1m
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: deep1m

Benchmarking: faiss on deep1m
  Vectors: (1000000, 96), Queries: (10000, 96)
  Metric: l2
  Verifying data integrity (Leakage Check)...
‚õî WARNING: Potential Data Leakage detected! Query vectors found in index.
  Applying tuned parameters for deep1m

  Index: IVF1024_L2
    Building Index (Once)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=1.0000, Latency_p50=0.46ms
    Run 2/3: Searching...    Run 2: Recall@10=1.0000, Latency_p50=0.45ms
    Run 3/3: Searching...    Run 3: Recall@10=1.0000, Latency_p50=0.46ms
  Applying tuned parameters for deep1m
  Skipping IVF1024_IP: Metric mismatch
      Results: faiss_deep1m (runs=3)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std)  ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.8048 ¬± 0.0000     ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 0.4565 ¬± 0.0032     ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 0.7718 ¬± 0.0064     ‚îÇ
‚îÇ QPS              ‚îÇ 2109.3170 ¬± 15.0254 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 12.5069 ¬± 0.0000    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/faiss/deep1m_faiss_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: faiss
Datasets: random
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: random

Benchmarking: faiss on random
  Vectors: (1000000, 128), Queries: (10000, 128)
  Metric: l2
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for random

  Index: IVF1024_L2
    Building Index (Once)...
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...    Run 1: Recall@10=0.4483, Latency_p50=0.39ms
    Run 2/3: Searching...    Run 2: Recall@10=0.4483, Latency_p50=0.39ms
    Run 3/3: Searching...    Run 3: Recall@10=0.4483, Latency_p50=0.38ms
  Applying tuned parameters for random
  Skipping IVF1024_IP: Metric mismatch
      Results: faiss_random (runs=3)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std)  ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 0.4483 ¬± 0.0000     ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.0450 ¬± 0.0000     ‚îÇ
‚îÇ MRR              ‚îÇ 0.9869 ¬± 0.0000     ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 0.3851 ¬± 0.0017     ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 0.5351 ¬± 0.0184     ‚îÇ
‚îÇ QPS              ‚îÇ 2578.4943 ¬± 18.7522 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 12.3113 ¬± 0.0000    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/faiss/random_faiss_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: faiss
Datasets: msmarco
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: msmarco

Benchmarking: faiss on msmarco
  Vectors: (100000, 768), Queries: (1000, 768)
  Metric: cosine
‚ö†Ô∏è  Dataset too small for 1000 warmup queries. Auto-reduced to 200.
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for msmarco
  Skipping IVF1024_L2: Metric mismatch
  Applying tuned parameters for msmarco

  Index: IVF1024_IP
    Building Index (Once)...
WARNING clustering 10000 points to 1024 centroids: please provide at least 39936 training points
    Running 200 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 1: Recall@10=1.0000, Latency_p50=0.64ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 2: Recall@10=1.0000, Latency_p50=0.64ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Recall 1.00 is outside expected range 0.6-0.95 for msmarco.
    Run 3: Recall@10=1.0000, Latency_p50=0.65ms
     Results: faiss_msmarco (runs=3)      
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std)  ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.5910 ¬± 0.0000     ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 0.6436 ¬± 0.0058     ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 0.8940 ¬± 0.0191     ‚îÇ
‚îÇ QPS              ‚îÇ 1544.6041 ¬± 14.4657 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 5.4988 ¬± 0.0000     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/faiss/msmarco_faiss_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
============================================================
VectorDB Benchmark Framework
============================================================

VectorDB Benchmark
Databases: faiss
Datasets: glove
Mode: Exploratory
Runs per config: 3 (Build Once, Search Many)


Loading dataset: glove

Benchmarking: faiss on glove
  Vectors: (390000, 100), Queries: (10000, 100)
  Metric: cosine
  Verifying data integrity (Leakage Check)...
  Applying tuned parameters for glove
  Skipping IVF1024_L2: Metric mismatch
  Applying tuned parameters for glove

  Index: IVF1024_IP
    Building Index (Once)...
WARNING clustering 39000 points to 1024 centroids: please provide at least 39936 training points
    Running 1000 warm-up queries...
    Starting 3 Search Runs...
    Run 1/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 1: Recall@10=1.0000, Latency_p50=0.84ms
    Run 2/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 2: Recall@10=1.0000, Latency_p50=0.84ms
    Run 3/3: Searching...
    ‚ö†Ô∏è  Suspicious: Precision@1 is 100%.
    Run 3: Recall@10=1.0000, Latency_p50=0.81ms
      Results: faiss_glove (runs=3)       
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Metric           ‚îÉ Value (Mean ¬± Std)  ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Recall@10        ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Recall@100       ‚îÇ 0.8760 ¬± 0.0000     ‚îÇ
‚îÇ MRR              ‚îÇ 1.0000 ¬± 0.0000     ‚îÇ
‚îÇ Latency p50 (ms) ‚îÇ 0.8311 ¬± 0.0141     ‚îÇ
‚îÇ Latency p99 (ms) ‚îÇ 1.2733 ¬± 0.0415     ‚îÇ
‚îÇ QPS              ‚îÇ 1181.5058 ¬± 22.2486 ‚îÇ
‚îÇ Build Time (s)   ‚îÇ 4.5945 ¬± 0.0000     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Exported JSON to results/faiss/glove_faiss_results.json
Exported CSV to results/results.csv
Exported LaTeX tables to results/tables
Generated plots in results/plots

Benchmark complete!
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database pgvector --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
üõë Stopping pgvector...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...

============================================================
 PREPARING BENCHMARK FOR: CHROMA
============================================================
üöÄ Starting chroma...
‚è≥ Waiting 30s for chroma...

‚ñ∂Ô∏è  Running: chroma on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database chroma --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting chroma...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for chroma...

‚ñ∂Ô∏è  Running: chroma on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database chroma --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting chroma...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for chroma...

‚ñ∂Ô∏è  Running: chroma on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database chroma --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting chroma...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for chroma...

‚ñ∂Ô∏è  Running: chroma on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database chroma --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ôªÔ∏è  RESET: Restarting chroma...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...
‚è≥ Waiting 30s for chroma...

‚ñ∂Ô∏è  Running: chroma on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database chroma --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
üõë Stopping chroma...
üßπ Deleting local volumes folder: /home/ashenrashmike2000/RAGdbEval/volumes...

============================================================
 PREPARING BENCHMARK FOR: LANCEDB
============================================================

‚ñ∂Ô∏è  Running: lancedb on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database lancedb --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: lancedb on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database lancedb --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: lancedb on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database lancedb --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: lancedb on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database lancedb --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: lancedb on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database lancedb --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.

============================================================
 PREPARING BENCHMARK FOR: FAISS
============================================================

‚ñ∂Ô∏è  Running: faiss on sift1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database faiss --dataset sift1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: faiss on deep1m...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database faiss --dataset deep1m --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: faiss on random...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database faiss --dataset random --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: faiss on msmarco...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database faiss --dataset msmarco --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
‚ùÑÔ∏è  Cooling down...

‚ñ∂Ô∏è  Running: faiss on glove...
Executing: "/usr/bin/python" "/home/ashenrashmike2000/RAGdbEval/scripts/run_benchmark.py" --database faiss --dataset glove --runs 3 --export json csv latex plots
‚úÖ Benchmark Run Successful.
